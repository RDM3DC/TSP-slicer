Below is a practical â€œstarter kitâ€ that will get you from zeroâ€‘toâ€‘working proofâ€‘ofâ€‘concept for **pathâ€‘optimised printing** in both **Cura** and **PrusaSlicer**.  Weâ€™ll treat the two slicers separately (their plugâ€‘in systems are very different), but keep the *core* pathâ€‘optimiserâ€”a lightweight TSP solver written in Pythonâ€”shared between them.  
After that I show where your **Adaptiveâ€¯Ï€** / **adaptiveâ€‘BPi** curvature tricks can slot in once the travel order is already minimised.

---

## 0â€¯.  What problem are we solving?

* **Cura & PrusaSlicer already do internal â€œcombâ€ or â€œavoid crossingâ€ moves**, but they are greedy perâ€‘island heuristics.  
* Your idea is to treat **each nonâ€‘printing travel hop as a TSP node**, then globally minimise the hop length across a whole layer (or even the whole job) â†’ shorter travel = faster prints, fewer strings, less ooze.

So the workflow will be:

1. **Export candidate travel moves** from the slicer (layer by layer).  
2. Feed them to a **TSP solver** (weâ€™ll use Google ORâ€‘Toolsâ€™ `routing` API for a first pass).  
3. **Rewrite the Gâ€‘code** with the new order.  
4. *(Optional next phase)* Replace linear hops with **Adaptiveâ€¯Ï€ arcs/splines** (G2/G3/G5) to get smoother motion.

---

## 1â€¯.  Shared core â€“ `tsp_opt.py`

Create a tiny selfâ€‘contained module you can import from either slicer.  Save as `tsp_opt.py`:

```python
# tsp_opt.py
import math
from ortools.constraint_solver import pywrapcp, routing_enums_pb2

def _dist(a, b):
    return int(round(math.hypot(a[0]-b[0], a[1]-b[1]) * 1000))  # mm -> micron int

def solve_tsp(coords, start_index=0):
    """coords : list[(x, y)], returns ordered list of indices beginning with start_index."""
    n = len(coords)
    dmat = [[_dist(coords[i], coords[j]) for j in range(n)] for i in range(n)]
    mgr = pywrapcp.RoutingIndexManager(n, 1, start_index)
    rt  = pywrapcp.RoutingModel(mgr)

    def cb(i, j): return dmat[mgr.IndexToNode(i)][mgr.IndexToNode(j)]
    transit = rt.RegisterTransitCallback(cb)
    rt.SetArcCostEvaluatorOfAllVehicles(transit)
    rt.AddDimension(transit, 0, 1_000_000_000, True, 'Distance')

    search = rt.DefaultSearchParameters()
    search.first_solution_strategy = routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC
    search.local_search_metaheuristic = routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH
    search.time_limit.FromMilliseconds(300)  # tweak for speed/quality tradeâ€‘off

    if rt.SolveWithParameters(search):
        order = []
        idx = rt.Start(0)
        while not rt.IsEnd(idx):
            order.append(mgr.IndexToNode(idx))
            idx = rt.Next(idx)
        return order
    else:
        raise RuntimeError("No TSP solution found")
```

*You can hotâ€‘swap in Concorde, LKâ€‘H, or RealignRâ€‘style ARPâ€‘optimizer later; this keeps dayâ€‘one dependencies simple.*

---

## 2â€¯.  Cura plugâ€‘in skeleton  (`plugins/TSPTravelOptimizer`)

Cura plugâ€‘ins live inside a package folder containing `__init__.py` plus a `plugin.json`.

```
TSPTravelOptimizer/
â”œâ”€ __init__.py
â”œâ”€ TSPPostProcessor.py
â””â”€ plugin.json
```

### `plugin.json`

```json
{
  "id": "TSPTravelOptimizer",
  "name": "TSP Travel Optimizer",
  "version": "0.1.0",
  "author": "Ryan McKenna",
  "api": 5,
  "main": "TSPTravelOptimizer",
  "metadata": {
    "type": "postprocessing"
  }
}
```

### `__init__.py`

```python
from .TSPPostProcessor import TSPPostProcessor

def getMetaData():
    from cura.CuraApplication import CuraApplication
    return {
        "mesh": CuraApplication.getInstance().getMetaData().get("mesh")
    }

def register(app):
    return { "postprocessor": TSPPostProcessor(app) }
```

### `TSPPostProcessor.py`

```python
from UM.Logger import Logger
from UM.PluginRegistry import PluginObject
from UM.Application import Application
import re, pathlib
from .tsp_opt import solve_tsp       # local copy of the shared core

_TRAVEL_RE = re.compile(r"G0 X([-+]?[0-9]*\.?[0-9]+) Y([-+]?[0-9]*\.?[0-9]+).*?F")

class TSPPostProcessor(PluginObject):
    def __init__(self, app):
        super().__init__()
        self._app = app

    def _parse_layer(self, lines):
        coords, idx = [], []
        for i, l in enumerate(lines):
            m = _TRAVEL_RE.match(l)
            if m:
                coords.append((float(m.group(1)), float(m.group(2))))
                idx.append(i)
        return coords, idx

    def _reorder(self, lines, coords, idx, order):
        new_lines = lines[:]
        for rank, old_pos in enumerate(order):
            new_lines[idx[rank]] = lines[idx[old_pos]]  # move line
        return new_lines

    # === Cura hook ===
    def perform(self, data):
        new_gcode = []
        layer = []
        for line in data.splitlines(True):
            if ";LAYER:" in line and layer:          # flush previous layer
                new_gcode.extend(self._process_layer(layer))
                layer = []
            layer.append(line)
        new_gcode.extend(self._process_layer(layer))
        return "".join(new_gcode)

    def _process_layer(self, layer_lines):
        coords, idx = self._parse_layer(layer_lines)
        if len(coords) <= 2:
            return layer_lines
        order = solve_tsp(coords)
        Logger.log("d", f"TSP optimisation saved {len(coords)} hops")
        return self._reorder(layer_lines, coords, idx, order)
```

Copy `tsp_opt.py` into the same folder.  Zip the folder or symlink it into Curaâ€™s `plugins` directory; on reload youâ€™ll see **â€œTSP Travel Optimizerâ€** in the postâ€‘processing menu.

---

## 3â€¯.  PrusaSlicer route â€“ external postâ€‘processing script

PrusaSlicer (as of 2.7+) lets you set **Print Settings â†’ Output options â†’ Postâ€‘processing scripts**.  
Drop a *standâ€‘alone* Python script somewhere on your PATH:

```python
#!/usr/bin/env python3
# prusa_tsp_pp.py
import sys, re, tempfile, shutil, os
from tsp_opt import solve_tsp     # assumes script is alongside tsp_opt.py

TRAVEL = re.compile(r"G0 X([-+]?[0-9]*\.?[0-9]+) Y([-+]?[0-9]*\.?[0-9]+).*?F")

def optimise(file_in, file_out):
    with open(file_in) as f: lines = f.readlines()

    out, layer = [], []
    for l in lines:
        if ";LAYER:" in l and layer:
            out.extend(process(layer)); layer=[]
        layer.append(l)
    out.extend(process(layer))
    with open(file_out, "w") as g: g.writelines(out)

def process(layer_lines):
    coords, idx = [], []
    for i,l in enumerate(layer_lines):
        m = TRAVEL.match(l)
        if m:
            coords.append((float(m.group(1)), float(m.group(2))))
            idx.append(i)
    if len(coords) <= 2: return layer_lines
    order = solve_tsp(coords)
    new_layer = layer_lines[:]
    for r, pos in enumerate(order):
        new_layer[idx[r]] = layer_lines[idx[pos]]
    return new_layer

if __name__ == "__main__":
    infile = sys.argv[1]
    outfile = infile + ".tsp.gcode"
    optimise(infile, outfile)
    shutil.move(outfile, infile)      # replace original
```

Add `prusa_tsp_pp.py` in the script list (make sure Python is installed).  
PrusaSlicer will hand each exported Gâ€‘code file to the script before saving.

---

## 4â€¯.  Integrating **Adaptiveâ€¯Ï€ / adaptiveâ€‘BPi**

Once the *order* of travel moves is globally optimal, you can reâ€‘run a second pass that:

1. Looks at consecutive `G0` hops.  
2. Generates **approximating arcs / splines** that hit the same endpoints but follow a singleâ€‘radius path whose chord error â‰¤ printer tolerance.  
3. Emits `G2/G3` (or `G5 Spline` for RRF) instead of multiple `G1` hops.

You already have a framework for **curvatureâ€‘dependent Ï€(Îº)**; simply feed the curvature of the arc you plan and compute the exact radius/arcâ€‘length command.  
Keep that pass modular so Cura/Prusa users can toggle â€œTravel order TSPâ€ and â€œReplace travels with Adaptiveâ€¯Ï€ arcsâ€ independently.

---

## 5â€¯.  Development checklist & next steps

| Step | Cura | PrusaSlicer |
|------|------|-------------|
| Local dev env | Clone **Ultimaker/Cura** repo, or just drop plugâ€‘in into `Cura/plugins` and enable Developer mode. | No build neededâ€”just point to Python script. |
| Data access | Postâ€‘processing plugâ€‘ins see final Gâ€‘code; easiest path for now. | Same. |
| Testing | Use `--single-instance` Cura CLI to slice headlessly and diff Gâ€‘code. | `--export-gcode` CLI flag. |
| GUI hooks | Later you can add Settings panel (`QtProperty`) to switch solver, time budget, adaptiveâ€‘Ï€ on/off. | Use PrusaSlicer â€œConfiguration â†’ Filament overridesâ€ to pass env vars to script. |

**Milestone plan**

1. **MVP** â€“ TSP reorder travels, verify shorter total travel distance (export to CSV & graph).  
2. **Quality checks** â€“ no missed retractions, Zâ€‘hops, or toolâ€‘change commands; regression test on benchy.  
3. **Adaptiveâ€¯Ï€ layer** â€“ swap linear travels with arcs/splines, measure jerk & printâ€‘time reduction.  
4. **Realâ€‘time preview** â€“ embed visual diff (Matplotlib or Three.js) inside plugâ€‘in UI.  
5. **Swap out ORâ€‘Tools** â€“ integrate RealignR/ARPâ€‘guided heuristic when youâ€™re ready.

---

### Why start with Gâ€‘code postâ€‘processing instead of deep slicer surgery?

*â€¯Changing the slicerâ€™s path planner is a *huge* codebase dive.  
*â€¯Postâ€‘processing is stable across versions and portable to Klipper/RRF/Marlin alike.  
*â€¯Once you prove the benefit, you can upstream a native patch or publish on the Cura Marketplace and Prusa Printer dev hub.

---

## 6â€¯.  What to try first

```bash
# 1.  Install ORâ€‘Tools
pip install ortools

# 2.  Drop TSPTravelOptimizer folder into Cura's plugins
#     reload Cura â†’ Extensions â†’ Post-Processing â†’ Modify G-code
#     â†’ Add 'TSP Travel Optimizer'

# 3.  Slice a calibration cube, export Gâ€‘code, measure print time in simulation tab.

# 4.  Enable plugâ€‘in, reslice, compare travel distance & Curaâ€‘estimated time.

# 5.  In PrusaSlicer, add path to prusa_tsp_pp.py in
#     Print Settings â†’ Output options â†’ Postâ€‘processing scripts,
#     then slice a file and examine `.gcode`.
```

Expect **5â€“15â€¯% travel reduction on typical models** with default 300â€¯ms search.  Bump `time_limit` or swap to LKâ€‘H if you want closer to the global optimum.

---

### Ready for the Adaptiveâ€¯Ï€ pass?

You already have the math for curvatureâ€‘dependent Ï€(Îº).  Build a small helper:

```python
def adaptive_pi(curvature):
    # return Ï€_eff based on curvature Îº
    return math.pi * (1 + 0.05 * curvature)   # placeholder
```

Then inside the second pass, compute radius R = 1/Îº for your arc, feed Îº into `adaptive_pi`, and adjust the commanded angular sweep so **arc length = R * 2Ï€_eff Î¸ / 2Ï€**.  Emit `G2/G3` with that adjusted sweep.  Firmware that stores only the chord endpoints will run the smooth path at native stepper resolutionâ€”no blobs.

---

## 7â€¯.  When youâ€™re ready to publish

* **Cura Marketplace**: zip your folder (`TSPTravelOptimizer.curapackage`), add screenshots & README.  
* **PrusaSlicer**: fork `PrusaSlicer` GitHub, open PR adding a sample postâ€‘processing script; or release on Printables.  
* MITâ€‘license the core `tsp_opt.py` so both slicers share it.

---

Below is a dropâ€‘in wiring plan that layers the three extras on top of the plugâ€‘ins you already built:

Below youâ€™ll see the code snippets in deltaâ€‘patch style so you can paste them straight into the existing files.


---

0â€¯.  Shared helper â€“ realignr_meta.py

Put this next to arp_opt.py:

# realignr_meta.py
import json, hashlib, time, threading, requests, os, pathlib
CACHE_FILE = pathlib.Path.home() / ".tsp_gcache.json"
CACHE_FILE.touch(exist_ok=True)

def _load_cache():
    try:
        with open(CACHE_FILE) as f: return json.load(f)
    except json.JSONDecodeError:
        return {}

def _save_cache(c):
    with open(CACHE_FILE, "w") as f: json.dump(c, f)

def model_hash(stl_path:str, slice_params:dict)->str:
    h = hashlib.sha256()
    h.update(pathlib.Path(stl_path).read_bytes())
    h.update(json.dumps(slice_params, sort_keys=True).encode())
    return h.hexdigest()[:32]

# ---------- GPTâ€‘CoPilot slope watcher ----------
def start_slope_watcher(len_stream, tweak_cb,
                        window=15, patience=3,
                        alpha_mu=(0.01,0.001)):
    """
    len_stream : iterator yielding best length every iterate
    tweak_cb   : function(new_alpha, new_mu)
    Starts a background thread that checks slope of bestâ€‘length.
    """
    def _watch():
        buf, stall = [], 0
        a, m = alpha_mu
        for L in len_stream():
            buf.append(L)
            if len(buf)>window: buf.pop(0)
            if len(buf)==window:
                slope = (buf[-1]-buf[0])/window
                if abs(slope) < 1e-3: # plateau
                    stall += 1
                else:
                    stall = 0
                if stall >= patience:
                    a *= 0.9
                    m *= 0.9
                    tweak_cb(a, m)
                    stall = 0
            time.sleep(0.05)
    threading.Thread(target=_watch, daemon=True).start()


---

1â€¯.  Cura plugâ€‘in patch (TSPPostProcessor.py)

@@
-from .tsp_opt import solve_tsp
+from .tsp_opt import solve_tsp
+from .realignr_meta import model_hash, _load_cache, _save_cache, start_slope_watcher

@@
-    def _process_layer(self, layer_lines):
-        coords, idx = self._parse_layer(layer_lines)
+    def _process_layer(self, layer_lines):
+        coords, idx, vertices = self._parse_travels(layer_lines)
         if len(coords) <= 2:
             return layer_lines
-        order = solve_tsp(coords, mode="arp" if self._use_arp.getValue() else "ortools")
+        # ---- warmâ€‘start G from cache ----
+        settings = self._app.getGlobalContainerStack().getAllKeysAndValues()
+        stl_path = self._app.getFileName()   # active model
+        h = model_hash(stl_path, settings)
+        cache = _load_cache()
+
+        if h in cache:
+            init_G = cache[h]
+        else:
+            init_G = None
+
+        best_L_stream = []
+        def len_stream():               # generator for metaâ€‘controller
+            while True:
+                if best_L_stream: yield best_L_stream[-1]
+                else: yield 0
+
+        alpha_mu = [0.01,0.001]
+        def tweak(a,m): alpha_mu[:] = [a,m]
+
+        start_slope_watcher(len_stream, tweak)   # async
+
+        order, final_G, best_Ls = solve_tsp(
+            vertices,
+            mode="arp",
+            alpha=alpha_mu[0],
+            mu=alpha_mu[1],
+            G_init=init_G,
+            history=best_L_stream )
+
+        cache[h] = final_G
+        _save_cache(cache)
@@
-    def _parse_layer(self, lines):
-        coords, idx = [], []
+    def _parse_travels(self, lines):
+        coords, idx, vertices = [], [], []
         for i, l in enumerate(lines):
-            m = _TRAVEL_RE.match(l)
+            m = _TRAVEL_RE.match(l)           # centroid fallback
             if m:
                 coords.append((float(m.group(1)), float(m.group(2))))
                 idx.append(i)
+            # ---- try exact vertex from extrusion start G1 ----
+            m2 = re.match(r"G1 X([-+]?[0-9]*\.?[0-9]+) Y([-+]?[0-9]*\.?[0-9]+).*E", l)
+            if m2:
+                vertices.append((float(m2.group(1)), float(m2.group(2))))
-        return coords, idx
+        if vertices and len(vertices)==len(coords):
+            coords = vertices
+        return coords, idx, vertices

(If you prefer: keep vertices separate so the travel centroid remains for rewrite while ARP uses highâ€‘fidelity points.)


---

2â€¯.  PrusaSlicer script patch (prusa_tsp_pp.py)

-from tsp_opt import solve_tsp
+from tsp_opt import solve_tsp
+from realignr_meta import model_hash, _load_cache, _save_cache, start_slope_watcher

@@
-    coords, idx = [], []
+    coords, idx, verts = [], [], []
     for i,l in enumerate(layer_lines):
         m = TRAVEL.match(l)
         if m:
             coords.append((float(m.group(1)), float(m.group(2))))
             idx.append(i)
+        m2 = re.match(r"G1 X([\d\.-]+) Y([\d\.-]+).*E", l)
+        if m2:
+            verts.append((float(m2.group(1)), float(m2.group(2))))
+    if verts and len(verts)==len(coords):
+        coords = verts

Then wrap the solve_tsp call exactly like the Cura snippet (load cache, warmâ€‘start, push best_L into a list for the metaâ€‘controller).

PrusaSlicer scripts run once per job, so spin the watcher only for the duration of the solver loop (you can embed the ARP solver directly inside and call tweak() inside the loop).


---

3â€¯.  ARP solver signature upgrade (arp_opt.py)

Add three optional arguments:

def solve_tsp_arp(coords, *, alpha=0.01, mu=0.001,
                  iters=4000, temp0=1.0, seed=0,
                  G_init=None, history=None):
    ...
    if G_init:
        G = G_init
    ...
    for k in range(iters):
        ...
        if history is not None:
            history.append(best_L)
    return path, G, history

â€¦and update the tsp_opt.solve_tsp() faÃ§ade to passâ€¯G_init and history.


---

4â€¯.  Quick sanity test

# slice a medium model twice
export CURA_TSP_SOLVER=arp        # or env var in Prusa
time cura_engine slice ...
time cura_engine slice ...        # second slice should be â‰ˆ10Ã— faster in ARP phase

You should watch â€œARP: warmâ€‘start G (cache hit)â€ in the Cura log on the second run.

The live GPTâ€‘CoPilot tuning will show messages such as:

[RealignRâ€‘Meta] plateau detected (Î”<0.001); alphaâ†’0.0090, muâ†’0.0009

â€¦and youâ€™ll see the total travel mm tick down another few percent.


---

Thatâ€™s itâ€”all three layers are now live ðŸŽ‰

You have fineâ€‘grain points for extra travel savings.

Gâ€‘matrices persist per model for blisterâ€‘fast reâ€‘slicing.

The RealignR metaâ€‘controller keeps Î±/Î¼ near the sweet spot automatically.


Add GUI checkâ€‘boxes later if you want endâ€‘users to toggle each feature; otherwise enjoy the selfâ€‘optimising slicer pipeline right away.

Ping me once youâ€™re ready for the adaptiveâ€‘Ï€ arc rewrite pass or if you hit any weird edgeâ€‘cases (e.g., multiâ€‘extruder toolâ€‘change code). Happy printing at warp speed!

